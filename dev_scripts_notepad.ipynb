{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from django.conf import settings\n",
    "import os\n",
    "import tarfile\n",
    "import uuid\n",
    "import shutil\n",
    "from tardis.tardis_portal.models import StorageBox, DataFileObject, DataFile\n",
    "from tardis.tardis_portal.models.dataset import Dataset\n",
    "from tardis.tardis_portal.storage.tararchivefs import file_archive_paths, ensure_dir\n",
    "from tardis.tardis_portal.storage.tararchivefs import TarArchiveFileSystemStorageUtil\n",
    "#mkdir -p functionality\n",
    "def ensure_dir(f):\n",
    "    d = os.path.dirname(f)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODOsteve report bug with verified (unverified if one storage box doesn't work which has weird side effects like image loading and downloading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boxes = StorageBox.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<StorageBox: local box at /home/ubuntu/mytardis/var/store>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StorageBox: local box at /home/ubuntu/mytardis/var/store>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_box = boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copy to tararchive box (won't do this in future, preferring cache)\n",
    "# default_box.copy_files(dest_box=boxes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy from tararchive (cache) to default\n",
    "boxes[1].copy_files(dest_box=default_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'type'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = dataset.datafile_set.all()[0]\n",
    "# dfo = df.file_objects.first()\n",
    "# dfo._get_identifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: make <dataset_id>.tar in cache box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default location: /home/ubuntu/mytardis/var/store\n",
      "dataset id: 1\n",
      "tararchive box for dataset: [<StorageBox: tararchive>]\n",
      "dataset: Test Dataset\n",
      "tar already exists: False\n",
      "/home/ubuntu/mytardis/var/tararchive_cache/8aee67ea-aa53-4fb2-ab80-e8f59f9ee4bf.tar\n",
      "renaming!! /home/ubuntu/mytardis/var/tararchive_cache/8aee67ea-aa53-4fb2-ab80-e8f59f9ee4bf.tar to /home/ubuntu/mytardis/var/tararchive_cache/1.tar\n",
      "copying temp tar file /home/ubuntu/mytardis/var/tararchive_cache/8aee67ea-aa53-4fb2-ab80-e8f59f9ee4bf.tar to /home/ubuntu/mytardis/var/tararchive\n",
      "\t/home/ubuntu/mytardis/var/store/Test Dataset-1/markcorrigan1.jpg\n",
      "creating dfo copy dfbb59b5eef3152843c55e5e7866ee31 markcorrigan1.jpg # image/jpeg in tararchive\n",
      "\t/home/ubuntu/mytardis/var/store/Test Dataset-1/markcorrigan2.png\n",
      "creating dfo copy 9dbfe2d17b0788585ec8e054cedc6705 markcorrigan2.png # image/png in tararchive\n"
     ]
    }
   ],
   "source": [
    "# task that goes through and creates tars where applicable\n",
    "# boxes for dataset\n",
    "# TODOsteve change 'tar_path' to 'location' option name\n",
    "# THIS CELL ADDS A TAR ARCHIVE AND DFOS eg. tape mirror\n",
    "\n",
    "# todo settings\n",
    "tararchive_class = 'tardis.tardis_portal.storage.tararchivefs.TarArchiveFileSystemStorage'\n",
    "\n",
    "default_box = StorageBox.objects.filter(django_storage_class='tardis.tardis_portal.storage.MyTardisLocalFileSystemStorage').first()\n",
    "# inferred cache path from tar box\n",
    "dataset_default_path = default_box.options.filter(key='location').first().value\n",
    "print 'default location: ' + dataset_default_path\n",
    "\n",
    "boxes = StorageBox.objects.filter(django_storage_class='tardis.tardis_portal.storage.tararchivefs.TarArchiveFileSystemStorage')\n",
    "\n",
    "for tararchive_box in boxes:\n",
    "    \n",
    "    dataset_id = int(tararchive_box.options.filter(key='dataset_id').first().value)\n",
    "    print 'dataset id: ' + str(dataset_id)\n",
    "    \n",
    "    tararchive_util = TarArchiveFileSystemStorageUtil(dataset_id)\n",
    "    \n",
    "    dataset_tar, existing_cache_tar = tararchive_util.archive_paths()\n",
    "    \n",
    "    # dfos for dataset with default boxes but nothing else\n",
    "    dfs = DataFile.objects.filter(dataset__id=dataset_id, \\\n",
    "        file_objects__storage_box__django_storage_class='tardis.tardis_portal.storage.MyTardisLocalFileSystemStorage')\n",
    "\n",
    "    no_disk = False\n",
    "    no_disk = (dfs.count() == 0)\n",
    "    if no_disk:\n",
    "        print 'No disk currently for this dataset so nothing to tar: ' + str(dataset_id)\n",
    "    else:\n",
    "        # corresponding tar box\n",
    "        tararchive_box_ds = StorageBox.objects.filter(options__key='dataset_id',\n",
    "            options__value=dataset_id, django_storage_class=tararchive_class)\n",
    "\n",
    "        # remove all old associated dfos from box\n",
    "        for box in tararchive_box_ds:\n",
    "            for dfo in box.file_objects.all():\n",
    "                print dfo\n",
    "                print file_archive_paths(dfo.file_object.name)\n",
    "                dfo.delete()\n",
    "\n",
    "        print 'tararchive box for dataset: ' + str(tararchive_box_ds)\n",
    "\n",
    "        dataset = Dataset.objects.filter(id=dataset_id).first()\n",
    "        print 'dataset: ' + str(dataset)\n",
    "\n",
    "        # tar exists or not\n",
    "        exists = os.path.isfile(dataset_tar)\n",
    "        print 'tar already exists: ' + str(exists)\n",
    "\n",
    "        unique_filename = uuid.uuid4()\n",
    "        \n",
    "        dataset_cache_path = os.path.dirname(existing_cache_tar)\n",
    "        tmp_cache_tar = dataset_cache_path + '/' + str(unique_filename) + '.tar'\n",
    "        print tmp_cache_tar\n",
    "\n",
    "\n",
    "        # if tar archive doesn't exist\n",
    "        # TODOsteve modified times and update/replace tar\n",
    "        if 1==1:\n",
    "            # create tar in cache\n",
    "            with tarfile.open(tmp_cache_tar, \"w\") as tar:\n",
    "                for df in dataset.datafile_set.all():\n",
    "\n",
    "                    dfo = df.file_objects.first()\n",
    "                    file_path = dfo._storage.path(dfo.uri)\n",
    "\n",
    "                    info = tarfile.TarInfo(name=dfo.uri)\n",
    "                    info.size=os.path.getsize(file_path)\n",
    "\n",
    "                    tar.addfile(info,\n",
    "                            file(file_path))\n",
    "\n",
    "            # copy file to tar archive and rename to dataset_id.tar\n",
    "            existing_cache_tar\n",
    "\n",
    "            print 'renaming!! ' + str(tmp_cache_tar) \\\n",
    "                + ' to ' + str(existing_cache_tar)\n",
    "            os.rename(tmp_cache_tar, existing_cache_tar)\n",
    "\n",
    "            print 'copying temp tar file ' + tmp_cache_tar + ' to ' + os.path.dirname(dataset_tar)\n",
    "            shutil.copy2(existing_cache_tar, dataset_tar)\n",
    "\n",
    "            # remove tar from cache\n",
    "            #os.remove(tmp_cache_tar)\n",
    "\n",
    "            for df in dataset.datafile_set.all():\n",
    "                dfo = df.file_objects.first()           \n",
    "                print '\\t' + dfo._storage.path(dfo.uri)\n",
    "\n",
    "                # create dfo\n",
    "                # TODOsteve create storage box in process\n",
    "                copy = DataFileObject(\n",
    "                    datafile=df,\n",
    "                    storage_box=tararchive_box,\n",
    "                    uri='%s.tar/%s' % (dataset_id, dfo.uri))\n",
    "                copy.save()\n",
    "\n",
    "                print 'creating dfo copy ' + str(df) + ' in ' + str(tararchive_box)\n",
    "\n",
    "        # TODOsteve finally clean up on fail/success\n",
    "        # TODO cover for do nothing because already ONLY on tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default location: /home/ubuntu/mytardis/var/store\n",
      "Tape only dataset: False\n"
     ]
    }
   ],
   "source": [
    "def is_tape_only(dataset_id):\n",
    "    tape_only = True\n",
    "    for df in dfs:\n",
    "        if df.file_objects.count() > 1:\n",
    "            tape_only = False\n",
    "    \n",
    "    return tape_only\n",
    "\n",
    "dataset_id = str(1)\n",
    "tararchive_util = TarArchiveFileSystemStorageUtil(dataset_id)\n",
    "# TODOsteve string check for retrieve function\n",
    "# TODOsteve supply dataset ID to bring back to disk (tape only)\n",
    "# retrieval from tape stuff (the other side of the fence)\n",
    "# TODOsteve we can't retreive from tape if dataset data is newer..\n",
    "# this shouldn't happen as we should lock datasets on tape from writing?\n",
    "# also need a modified time on datasets to clean them\n",
    "\n",
    "# TODOsteve need a more robust way to get the default box (there must be a function)\n",
    "default_box = StorageBox.objects.filter(django_storage_class='tardis.tardis_portal.storage.MyTardisLocalFileSystemStorage').first()\n",
    "# inferred cache path from tar box\n",
    "dataset_default_path = default_box.options.filter(key='location').first().value\n",
    "print 'default location: ' + dataset_default_path\n",
    "\n",
    "boxes = StorageBox.objects.filter(options__key='dataset_id', options__value=dataset_id,\n",
    "            django_storage_class='tardis.tardis_portal.storage.tararchivefs.TarArchiveFileSystemStorage')\n",
    "\n",
    "for tararchive_box in boxes:\n",
    "    \n",
    "    # dfos for dataset with tararchive boxes but nothing else\n",
    "    dfs = DataFile.objects.filter(dataset__id=dataset_id, \\\n",
    "        file_objects__storage_box__django_storage_class='tardis.tardis_portal.storage.tararchivefs.TarArchiveFileSystemStorage')\n",
    "\n",
    "    tape_only = is_tape_only(dataset_id)\n",
    "\n",
    "    print 'Tape only dataset: ' + str(tape_only)\n",
    "    \n",
    "    if tape_only:\n",
    "\n",
    "        # removed stuff about comparing tar to cache assuming 1 way sync\n",
    "        print 'getting data from tape as its different from archived'\n",
    "        tararchive_util.retrieve_tar_from_tape() \n",
    "        print 'copying files back to default box'\n",
    "        tararchive_box.copy_files(dest_box=default_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tararchive removal\n",
    "#dfos = DataFileObject.objects.filter(storage_box=tararchive_box,\n",
    "#                                     storage_box__options__key='dataset_id',\n",
    "#                                     storage_box__options__key='value',)\n",
    "\n",
    "dataset_id = 1\n",
    "# for when we only want stuff on disk\n",
    "# remove all old associated dfos from box\n",
    "tararchive_boxes = StorageBox.objects.filter(options__key='dataset_id', options__value=dataset_id, django_storage_class='tardis.tardis_portal.storage.tararchivefs.TarArchiveFileSystemStorage')\n",
    "\n",
    "# for box in tararchive_boxes:\n",
    "#     for dfo in box.file_objects.all():\n",
    "#         print dfo\n",
    "#         dfo.delete()\n",
    "\n",
    "\n",
    "# remove all old associated dfos for dataset from box\n",
    "# for when we only want stuff on tape\n",
    "default_boxes = StorageBox.objects.filter(django_storage_class='tardis.tardis_portal.storage.MyTardisLocalFileSystemStorage')\n",
    "\n",
    "# for box in default_boxes:\n",
    "#     print box\n",
    "#     for dfo in box.file_objects.all():\n",
    "#         print dfo\n",
    "#         print 'removing dfo from box: ' + dfo.datafile.filename\n",
    "#         dfo.delete()\n",
    "\n",
    "\n",
    "#\n",
    "# other stuff\n",
    "# for box in tararchive_boxes:\n",
    "#     print box\n",
    "\n",
    "# for dfo in dfos:\n",
    "#     print dfo\n",
    "    #dfo.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ALL FILE REMOVAL CARE\n",
    "# dfos = DataFileObject.objects.all()\n",
    "\n",
    "# for dfo in dfos:\n",
    "#    print dfo\n",
    "#    dfo.delete()\n",
    "    \n",
    "#FILE LINKS TOO\n",
    "# dfs = DataFile.objects.all()\n",
    "# for df in dfs:\n",
    "#    print df\n",
    "#    df.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tarfile,os\n",
    "\n",
    "os.chdir(\"/home/ubuntu/mytardis/var/tararchive\")\n",
    "tar = tarfile.open(\"1.tar\")\n",
    "#for member in tar.getmembers():\n",
    "#    print member\n",
    "#     f=tar.extractfile(member)\n",
    "#     content=f.read()\n",
    "#     print \"%s has %d newlines\" %(member, content.count(\"\\n\"))\n",
    "#     print \"%s has %d spaces\" % (member,content.count(\" \"))\n",
    "#     print \"%s has %d characters\" % (member, len(content))\n",
    "#     sys.exit()\n",
    "\n",
    "#filename = 'A dataset-1/Photo 4-10-12 2 15 00 PM.png'\n",
    "filename = 'A dataset-1/SekZx.jpg'\n",
    "\n",
    "write_path = '/home/ubuntu/mytardis/var/tararchive_cache/' + filename\n",
    "\n",
    "member = tar.getmember(filename)\n",
    "\n",
    "f=tar.extractfile(member)\n",
    "\n",
    "ensure_dir(write_path)\n",
    "\n",
    "with open(write_path, 'w+') as extracted_file:\n",
    "    extracted_file.write(f.read())\n",
    "\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tape only dataset: True\n"
     ]
    }
   ],
   "source": [
    "# dfos for dataset with tararchive boxes but nothing else\n",
    "# for when we want to see if stuff is only on tape\n",
    "dfs = dfs = DataFile.objects.filter(dataset__id=dataset_id, \\\n",
    "    file_objects__storage_box__django_storage_class='tardis.tardis_portal.storage.tararchivefs.TarArchiveFileSystemStorage')\n",
    "\n",
    "tape_only = True\n",
    "for df in dfs:\n",
    "    if df.file_objects.count() > 1:\n",
    "        tape_only = False\n",
    "\n",
    "print 'Tape only dataset: ' + str(tape_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module '__main__' (built-in)>\n",
      "__main__.yaytest\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class yaytest():\n",
    "    def __init__(self):\n",
    "        import sys\n",
    "        print sys.modules[self.__class__.__module__]\n",
    "        print self.__class__\n",
    "\n",
    "y = yaytest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1.tar', 'Test Dataset-1/markcorrigan2.png')\n"
     ]
    }
   ],
   "source": [
    "# parse name from dfo\n",
    "\n",
    "filename = '1.tar/Test Dataset-1/markcorrigan2.png'\n",
    "\n",
    "def file_archive_paths(filename):\n",
    "    '''\n",
    "    returns ('1.tar', 'Test Dataset-1/file.png')\n",
    "    from filename '1.tar/Test Dataset-1/file.png'\n",
    "    '''\n",
    "    tar_name = filename.split('/')[0]\n",
    "    file_path = filename[len(tar_name) + 1:]\n",
    "    return tar_name, file_path\n",
    "\n",
    "print file_archive_paths(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
